{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false,
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "import requests, datetime, time, csv\n",
    "from bs4 import BeautifulSoup\n",
    "\n",
    "def get_soup(pageNum):\n",
    "    url = 'http://forum.u-car.com.tw/index.asp?page=' + str(pageNum) + '&category=19'\n",
    "    index_res = requests.get(url)\n",
    "    return BeautifulSoup(index_res.text)\n",
    "\n",
    "def get_linklist(soup):\n",
    "    link_list = []\n",
    "    for i in soup.select('a'):\n",
    "\n",
    "        if 'thread.asp' in i['href']:\n",
    "            link_list.append('http://forum.u-car.com.tw/' + i['href'])\n",
    "\n",
    "        counter = 0\n",
    "        while counter < len(link_list):\n",
    "            if len(link_list[counter]) == 51:\n",
    "                link_list[counter] += '&page=1'\n",
    "            counter += 1\n",
    "            \n",
    "    for i in set(link_list):\n",
    "        if len(i) == 59:\n",
    "            a = int(i[-2:])\n",
    "\n",
    "            while a > 4:\n",
    "                url = i[:57] + str(a)\n",
    "                if url not in link_list:\n",
    "                    link_list.append(url)\n",
    "                a -= 1\n",
    "\n",
    "        elif len(i) == 60:\n",
    "            a = int(i[-3:])\n",
    "\n",
    "            while a > 4:\n",
    "                url = i[:57] + str(a)\n",
    "                if url not in link_list:\n",
    "                    link_list.append(url)\n",
    "                a -= 1\n",
    "\n",
    "        elif len(i) == 58 and int(i[-1]) > 4:\n",
    "            a = int(i[-1:])\n",
    "\n",
    "            while a > 4:\n",
    "                url = i[:57] + str(a)\n",
    "                if url not in link_list:\n",
    "                    link_list.append(url)\n",
    "                a -= 1\n",
    "\n",
    "    return list(set(link_list))\n",
    "\n",
    "def crawl_thread(link):\n",
    "    thread_res = requests.get(link)\n",
    "    thread_res.encoding = 'utf-8'\n",
    "    thread_soup = BeautifulSoup(thread_res.text)\n",
    "    \n",
    "    \n",
    "    thread_data = []\n",
    "    for i in thread_soup.find_all(\"div\", { \"class\" : \"fd_cont\" }):\n",
    "        thread_data.append([\n",
    "            # date\n",
    "            i.find_all(\"div\", {\"class\":\"memberinfo_top_l\"})[0].text[:19].strip(),\n",
    "            # author\n",
    "            i.find_all(\"li\", {'class':'member_id'})[0].select('a')[0].string.strip(),\n",
    "            # content\n",
    "            i.find_all('div', {'class':'userwrite'})[0].text.strip()\n",
    "        ])\n",
    "    return thread_data\n",
    "\n",
    "pageNum = 1\n",
    "while True:\n",
    "    try:\n",
    "        for link in sorted(get_linklist(get_soup(pageNum))):\n",
    "            with open('u-car.csv', 'a', encoding='utf-8') as csvfile:\n",
    "                for data in crawl_thread(link):\n",
    "                    print(data[0],data[1],data[2],link)\n",
    "                    writer = csv.writer(csvfile, delimiter=',')\n",
    "                    writer.writerow([data[0],data[1],data[2],link])\n",
    "        pageNum += 1\n",
    "    except:\n",
    "        RetryCounter = 1\n",
    "        while RetryCounter <= 3:\n",
    "            print('retry after 2 sec...')\n",
    "            time.sleep(2)\n",
    "        break"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2015/07/13 11:45:26 firepro 好在沒等他,不然會買不起,只買的起Cayenne入門柴油D5 Momentum+為324萬元高階D5 Inscription是349萬元汽油版T6目前僅提供Inscription等級，售價372萬元\n"
     ]
    }
   ],
   "source": [
    "import requests, datetime, time, re\n",
    "import pandas as pd\n",
    "from bs4 import BeautifulSoup\n",
    "\n",
    "t1_url = 'http://forum.u-car.com.tw/thread.asp?forumid=285933&page=1'\n",
    "t1_res = requests.get(t1_url)\n",
    "t1_res.encoding = 'utf-8'\n",
    "t1_soup = BeautifulSoup(t1_res.text)\n",
    "\n",
    "for i in t1_soup.find_all(\"div\", { \"class\" : \"fd_box\" }):\n",
    "    print(\n",
    "        # date\n",
    "        i.find_all(\"div\", {\"class\":\"memberinfo_top_l\"})[0].text[:19],\n",
    "        # author\n",
    "        i.find_all(\"li\", {'class':'member_id'})[0].select('a')[0].string,\n",
    "        # content\n",
    "        i.find_all('div', {'class':'userwrite'})[0].text\n",
    "    )\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import requests, datetime, time, re\n",
    "import pandas as pd\n",
    "from bs4 import BeautifulSoup\n",
    "\n",
    "t1_url = 'http://forum.u-car.com.tw/thread.asp?forumid=285933&page=1'\n",
    "t1_res = requests.get(t1_url)\n",
    "t1_res.encoding = 'utf-8'\n",
    "t1_soup = BeautifulSoup(t1_res.text)\n",
    "\n",
    "        # title\n",
    "        i.find_all(\"div\", {'class': 'forumhead'})[0].text,"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.4.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
