{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false,
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "import json, csv\n",
    "import gensim\n",
    "\n",
    "model = gensim.models.Word2Vec.load_word2vec_format('autohome_word_only.vector',binary=False)\n",
    "autohome_count = csv.reader(open('autohome_count.csv', 'r'))\n",
    "\n",
    "target_words = ['U6','车','纳智捷','优6','价格','油耗']\n",
    "\n",
    "related_words = []\n",
    "for i in target_words:  \n",
    "    related_words.append([x for x,_ in model.most_similar(i)[0:5]])\n",
    "\n",
    "related_words_unpack = []\n",
    "for i in related_words:\n",
    "    for x in i:\n",
    "        related_words_unpack.append(x)\n",
    "\n",
    "count_dict = {row[0]:int(row[1]) for row in autohome_count if row[0] in related_words_unpack}\n",
    "\n",
    "with open('autohome_with_adj_n.csv','r') as raw_data:\n",
    "    csv_reader = csv.reader(raw_data)\n",
    "    a = []\n",
    "    for row in csv_reader:\n",
    "        for word in related_words_unpack:\n",
    "            if word in row[5] and [word, row[2]] not in a:\n",
    "                a.append([word, row[2]])\n",
    "\n",
    "dict_list= {word:[i[1] for i in a if i[0] == word][:5] for word in related_words_unpack}\n",
    "\n",
    "dataset = []\n",
    "for i in target_words:\n",
    "    dataset.append(\n",
    "        {'name':i,\n",
    "         'children': [{'topic':x,\n",
    "                       'rate':count_dict[x], \n",
    "                       'link':[\n",
    "                                {'title':y,'url':'https://www.google.ca/?gws_rd=ssl'} \n",
    "                                for y in dict_list[x]\n",
    "                              ]\n",
    "                      } for x,_ in model.most_similar(i)[0:5]]\n",
    "        }\n",
    "    )\n",
    "\n",
    "print(json.dumps(dataset, indent=4, ensure_ascii=False))\n",
    "    \n",
    "#with open('autohome.json','w') as outfile:\n",
    "#    outfile.write(json.dumps(dataset, outfile, indent=4, ensure_ascii=False))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['a', 'b', 'c']\n"
     ]
    }
   ],
   "source": [
    "abclist = [('a','1'),('b','2'),('c','3')]\n",
    "newlist = []\n",
    "for x,y in abclist:\n",
    "    newlist.append(x)\n",
    "\n",
    "print(newlist)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "import json, csv\n",
    "import gensim\n",
    "\n",
    "model = gensim.models.Word2Vec.load_word2vec_format('autohome_word_only.vector',binary=False)\n",
    "autohome_count = csv.reader(open('autohome_count.csv', 'r'))\n",
    "\n",
    "target_words = ['U6','车','纳智捷','优6','价格','油耗']\n",
    "\n",
    "related_words = []\n",
    "for i in target_words:  \n",
    "    related_words.append([x for x,_ in model.most_similar(i)[0:5]])\n",
    "\n",
    "related_words_unpack = []\n",
    "for i in related_words:\n",
    "    for x in i:\n",
    "        related_words_unpack.append(x)\n",
    "\n",
    "count_dict = {row[0]:int(row[1]) for row in autohome_count if row[0] in related_words_unpack}\n",
    "\n",
    "dataset = {\n",
    "    'name': 'autohome',\n",
    "    'children':[\n",
    "        {\n",
    "            'name':x,\n",
    "            'children': [\n",
    "                {\n",
    "                    'name': y,\n",
    "                    'size': count_dict[y]\n",
    "                } for y,_ in model.most_similar(x)[0:5]\n",
    "            ]\n",
    "        } for x in target_words\n",
    "    ] \n",
    "}\n",
    "\n",
    "print(json.dumps(dataset, indent=2, ensure_ascii=False))\n",
    "    \n",
    "with open('autohome_linked_data.json','w') as outfile:\n",
    "    outfile.write(json.dumps(dataset, outfile, indent=2, ensure_ascii=False))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "import json, csv\n",
    "import gensim\n",
    "\n",
    "model = gensim.models.Word2Vec.load_word2vec_format('autohome_word_only.vector',binary=False)\n",
    "autohome_count = csv.reader(open('autohome_count.csv', 'r'))\n",
    "\n",
    "target_words = ['U6','车','纳智捷','优6','上市','感觉']\n",
    "\n",
    "related_words = []\n",
    "for i in target_words:  \n",
    "    related_words.append([x for x,_ in model.most_similar(i)[0:5]])\n",
    "\n",
    "related_words_unpack = []\n",
    "for i in related_words:\n",
    "    for x in i:\n",
    "        related_words_unpack.append(x)\n",
    "\n",
    "count_dict = {row[0]:int(row[1]) for row in autohome_count if row[0] in related_words_unpack}\n",
    "\n",
    "a = []\n",
    "for i in target_words:\n",
    "    a.append(\n",
    "        {'name':i,\n",
    "         'children': [{'topic':x, 'rate':count_dict[x]} for x,_ in model.most_similar(i)[0:5]]\n",
    "        }\n",
    "    )\n",
    "\n",
    "print(json.dumps(a, indent=4, ensure_ascii=False))\n",
    "    \n",
    "#with open('autohome.json','w') as outfile:\n",
    "#    json.dumps(a, outfile, indent=4, ensure_ascii=False)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.4.3+"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
